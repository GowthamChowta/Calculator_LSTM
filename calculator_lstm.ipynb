{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "calculator_lstm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-lj8RDW5-i2D",
        "outputId": "56994968-0c1e-4073-a6cb-a49488116c14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.layers import LSTM,TimeDistributed,Dense,RepeatVector\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2tIMAgZ5_BjP",
        "colab": {}
      },
      "source": [
        "#All the numerical numbers\n",
        "num='0123456789'\n",
        "#All the characters\n",
        "chars=' 0123456789-+*/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IDBF2wUwA2k8",
        "colab": {}
      },
      "source": [
        "char_len=len(chars)\n",
        "char_indice=dict([(c,i) for i,c in enumerate(sorted(chars))])\n",
        "indices_char=dict([(i,c) for i,c in enumerate(sorted(chars))])\n",
        "Max_length=9 \n",
        "# 3 digits + symbol + 3 digits\n",
        "Max_out=7\n",
        "# 6 digits + if (-negative sign) -999*999= -998001\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3KMk4jaqYuJ0",
        "colab": {}
      },
      "source": [
        "def generate_symbol():\n",
        "  sym=['+','-','*','/']\n",
        "  return sym[random.randint(0,3)]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qpRAdjb2-qx-",
        "colab": {}
      },
      "source": [
        "#Function that generates train data\n",
        "def generate_data(count):\n",
        "  print('Generating {} data samples'.format(count))\n",
        "  X=[]\n",
        "  y=[]\n",
        "  while(count>0):\n",
        "    # num='0123456789' We are selecting random 3 digits from this string and then converting it to integer\n",
        "    in1=int(''.join(random.choices(num,k=random.randint(1,3))))\n",
        "    in2=int(''.join(random.choices(num,k=random.randint(1,3))))\n",
        "    \n",
        "    # Function that generated symbol\n",
        "    sym=generate_symbol()\n",
        "    if sym=='+':\n",
        "      out=in1+in2\n",
        "      inp=str(in1)+'+'+str(in2)\n",
        "    elif sym =='-':\n",
        "      out=in1-in2\n",
        "      inp=str(in1)+'-'+str(in2)\n",
        "    elif sym == '*':\n",
        "      out=in1*in2\n",
        "      inp=str(in1)+'*'+str(in2)\n",
        "    elif sym == '/':\n",
        "      try:\n",
        "        out=in1//in2\n",
        "        inp=str(in1)+'/'+str(in2)\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "    out=str(out)\n",
        "    # We want the length of the input string and output string to be same, hence padding the number with extra spaces\n",
        "    l1=Max_length-len(inp)\n",
        "    l2=Max_out-len(out)\n",
        "    inp=' '*l1+inp\n",
        "    out=' '*l2+out\n",
        "\n",
        "    X.append(inp)\n",
        "    y.append(out)\n",
        "    count=count-1\n",
        "\n",
        "  return X,y\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U7sIsg17kB0R",
        "outputId": "2fdd0cf1-1049-4ced-f52c-c55b678ab17f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "generate_data(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating 5 data samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['  514*943', '     99+2', '   57-752', '   307*35', '     49-9'],\n",
              " [' 484702', '    101', '   -695', '  10745', '     40'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_O4D1SKdBcKR",
        "outputId": "cbb23abf-cd49-4466-da65-f4e41d1354b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "training_samples=200000\n",
        "X,y=generate_data(training_samples)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating 200000 data samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z-hgeVyM-qZ1",
        "colab": {}
      },
      "source": [
        "# Encoding each character in input to one hot encoded vector.\n",
        "def encode(data):\n",
        "  r=np.zeros((len(data),len(chars)))\n",
        "  #print(r.shape)\n",
        "  for i,d in enumerate(data):\n",
        "      r[i,char_indice[d]]=1\n",
        "  return r"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ccZIlwBY-qRQ",
        "colab": {}
      },
      "source": [
        "X_new=np.zeros((training_samples,Max_length,char_len))\n",
        "y_new=np.zeros((training_samples,Max_out,char_len))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IVBw5EL5tc-w",
        "outputId": "b7aa6737-722f-442b-b855-00c9e2e150a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y[0],y[1],y[2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('      0', '      5', '    749')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VLINRMJx-qNW",
        "colab": {}
      },
      "source": [
        "# Encoding all the data generated\n",
        "for i in range(training_samples):\n",
        "  X_new[i]=encode(X[i])\n",
        "  y_new[i]=encode(y[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vDXtlwWL-qKc",
        "outputId": "ff955cdc-9a01-417c-86b6-5e61a6509b2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# X --  60k samples of max_length 15.\n",
        "# X_new -- 60k samples of max_length 7 and each of them is one hot encoded to a 15 dim vector.\n",
        "X_new.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200000, 9, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ksw4AS7V-qHi",
        "outputId": "fdbe1f74-a452-4c61-b34d-616de2e046a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_new.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200000, 7, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jGRVJMM6-qFf",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split( X_new, y_new, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CtskAtUQ-qCj",
        "outputId": "0b35a3d2-8a23-487e-8c9a-847118ce3114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(160000, 9, 15)\n",
            "(40000, 9, 15)\n",
            "(160000, 7, 15)\n",
            "(40000, 7, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2OLsLzSp-p_V",
        "colab": {}
      },
      "source": [
        "model=Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "92XyJ8NE-p81",
        "colab": {}
      },
      "source": [
        "# LSTM layer of 128 dimension. \n",
        "# Input-Shape is (7,12).  \n",
        "model.add(LSTM(256,input_shape=(Max_length,char_len)))\n",
        "\n",
        "# For each input (7,12) we will get 128 output vectors. \n",
        "# Output shape (None,128)\n",
        "\n",
        "model.add(RepeatVector(7))\n",
        "#In order to pass the encoder input to decoder LSTM. LSTM expects sequential data, so is expects input data to be 3 dim.\n",
        "# Hence we wii be sending the input 4 times, Or we are just duplicating the above code 4 times. So we get (None,7,128)\n",
        "model.add(LSTM(256,return_sequences=True))\n",
        "# This is a decoder model, so every time an input is given we should get an output. Hence return_sequences=True should be given.\n",
        "# As the input is given 7 times, we will get 7 outputs for each LSTM. Total 128 LSTMS hence (None,7,128).\n",
        "\n",
        "model.add(TimeDistributed(Dense(char_len,activation='softmax')))\n",
        "# Most important part, now we will give this (None,7,128) to this layer. So for one sequential input, we are getting (7,128) dimension vector.\n",
        "# 7-- 128 dimension vectors, y1,y2,y3,y4,y5,y6,y7. yi is output at timestep i. So after getting yi we have to apply dense layer and decide its class.\n",
        "# We have to do this for all the 4 outputs. Hence we add a time distributed dense layer and apply Dense layer on top of this. Which means\n",
        "# we are applying dense layer on each of yi.\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZMh2xWgb-p7U",
        "outputId": "6701b8fa-cd9d-48b8-f9b0-54700223d861",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_9 (LSTM)                (None, 256)               278528    \n",
            "_________________________________________________________________\n",
            "repeat_vector_5 (RepeatVecto (None, 7, 256)            0         \n",
            "_________________________________________________________________\n",
            "lstm_10 (LSTM)               (None, 7, 256)            525312    \n",
            "_________________________________________________________________\n",
            "time_distributed_5 (TimeDist (None, 7, 15)             3855      \n",
            "=================================================================\n",
            "Total params: 807,695\n",
            "Trainable params: 807,695\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Nb7-V0hc-p2v",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BCC33FbM-p0x",
        "outputId": "3677cd1c-fd93-4078-f8c5-2384880cec63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936
        }
      },
      "source": [
        "model.fit(X_train, y_train,batch_size=64,epochs=100,validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 160000 samples, validate on 40000 samples\n",
            "Epoch 1/100\n",
            "160000/160000 [==============================] - 103s 644us/step - loss: 0.7371 - accuracy: 0.7275 - val_loss: 0.5659 - val_accuracy: 0.7805\n",
            "Epoch 2/100\n",
            "160000/160000 [==============================] - 102s 635us/step - loss: 0.4751 - accuracy: 0.8088 - val_loss: 0.4170 - val_accuracy: 0.8289\n",
            "Epoch 3/100\n",
            "160000/160000 [==============================] - 102s 635us/step - loss: 0.3867 - accuracy: 0.8406 - val_loss: 0.3538 - val_accuracy: 0.8550\n",
            "Epoch 4/100\n",
            "160000/160000 [==============================] - 102s 636us/step - loss: 0.3260 - accuracy: 0.8670 - val_loss: 0.2914 - val_accuracy: 0.8821\n",
            "Epoch 5/100\n",
            "160000/160000 [==============================] - 102s 640us/step - loss: 0.2687 - accuracy: 0.8928 - val_loss: 0.2410 - val_accuracy: 0.9046\n",
            "Epoch 6/100\n",
            "160000/160000 [==============================] - 102s 640us/step - loss: 0.2111 - accuracy: 0.9186 - val_loss: 0.1983 - val_accuracy: 0.9238\n",
            "Epoch 7/100\n",
            "160000/160000 [==============================] - 103s 643us/step - loss: 0.1658 - accuracy: 0.9375 - val_loss: 0.1561 - val_accuracy: 0.9414\n",
            "Epoch 8/100\n",
            "160000/160000 [==============================] - 103s 644us/step - loss: 0.1371 - accuracy: 0.9488 - val_loss: 0.1419 - val_accuracy: 0.9464\n",
            "Epoch 9/100\n",
            "160000/160000 [==============================] - 104s 647us/step - loss: 0.1219 - accuracy: 0.9544 - val_loss: 0.1205 - val_accuracy: 0.9544\n",
            "Epoch 10/100\n",
            "160000/160000 [==============================] - 103s 641us/step - loss: 0.1103 - accuracy: 0.9585 - val_loss: 0.1170 - val_accuracy: 0.9554\n",
            "Epoch 11/100\n",
            "160000/160000 [==============================] - 102s 638us/step - loss: 0.1023 - accuracy: 0.9613 - val_loss: 0.1120 - val_accuracy: 0.9574\n",
            "Epoch 12/100\n",
            "160000/160000 [==============================] - 103s 644us/step - loss: 0.0947 - accuracy: 0.9643 - val_loss: 0.1075 - val_accuracy: 0.9587\n",
            "Epoch 13/100\n",
            "160000/160000 [==============================] - 101s 633us/step - loss: 0.0893 - accuracy: 0.9662 - val_loss: 0.1027 - val_accuracy: 0.9610\n",
            "Epoch 14/100\n",
            "160000/160000 [==============================] - 101s 632us/step - loss: 0.0855 - accuracy: 0.9679 - val_loss: 0.0944 - val_accuracy: 0.9632\n",
            "Epoch 15/100\n",
            "160000/160000 [==============================] - 101s 630us/step - loss: 0.0793 - accuracy: 0.9701 - val_loss: 0.0983 - val_accuracy: 0.9621\n",
            "Epoch 16/100\n",
            "160000/160000 [==============================] - 101s 632us/step - loss: 0.0758 - accuracy: 0.9713 - val_loss: 0.0953 - val_accuracy: 0.9638\n",
            "Epoch 17/100\n",
            "160000/160000 [==============================] - 101s 634us/step - loss: 0.0729 - accuracy: 0.9725 - val_loss: 0.1635 - val_accuracy: 0.9533\n",
            "Epoch 18/100\n",
            "160000/160000 [==============================] - 101s 633us/step - loss: 0.0700 - accuracy: 0.9739 - val_loss: 0.0846 - val_accuracy: 0.9676\n",
            "Epoch 19/100\n",
            "160000/160000 [==============================] - 101s 633us/step - loss: 0.0670 - accuracy: 0.9749 - val_loss: 0.0896 - val_accuracy: 0.9661\n",
            "Epoch 20/100\n",
            "160000/160000 [==============================] - 101s 634us/step - loss: 0.0639 - accuracy: 0.9763 - val_loss: 0.0851 - val_accuracy: 0.9681\n",
            "Epoch 21/100\n",
            "160000/160000 [==============================] - 101s 630us/step - loss: 0.0626 - accuracy: 0.9769 - val_loss: 0.0889 - val_accuracy: 0.9666\n",
            "Epoch 22/100\n",
            "160000/160000 [==============================] - 101s 633us/step - loss: 0.0593 - accuracy: 0.9781 - val_loss: 0.0904 - val_accuracy: 0.9668\n",
            "Epoch 23/100\n",
            "160000/160000 [==============================] - 101s 629us/step - loss: 0.0573 - accuracy: 0.9790 - val_loss: 0.0890 - val_accuracy: 0.9674\n",
            "Epoch 24/100\n",
            "160000/160000 [==============================] - 102s 635us/step - loss: 0.0552 - accuracy: 0.9799 - val_loss: 0.0868 - val_accuracy: 0.9684\n",
            "Epoch 25/100\n",
            "160000/160000 [==============================] - 101s 632us/step - loss: 0.0526 - accuracy: 0.9810 - val_loss: 0.0893 - val_accuracy: 0.9683\n",
            "Epoch 26/100\n",
            "160000/160000 [==============================] - 101s 632us/step - loss: 0.0506 - accuracy: 0.9817 - val_loss: 0.0919 - val_accuracy: 0.9681\n",
            "Epoch 27/100\n",
            "160000/160000 [==============================] - 101s 634us/step - loss: 0.0493 - accuracy: 0.9822 - val_loss: 0.0908 - val_accuracy: 0.9682\n",
            "Epoch 28/100\n",
            "160000/160000 [==============================] - 102s 635us/step - loss: 0.0462 - accuracy: 0.9835 - val_loss: 0.0891 - val_accuracy: 0.9695\n",
            "Epoch 29/100\n",
            "160000/160000 [==============================] - 102s 638us/step - loss: 0.0459 - accuracy: 0.9840 - val_loss: 0.0855 - val_accuracy: 0.9708\n",
            "Epoch 30/100\n",
            "160000/160000 [==============================] - 102s 637us/step - loss: 0.0425 - accuracy: 0.9851 - val_loss: 0.0891 - val_accuracy: 0.9703\n",
            "Epoch 31/100\n",
            "160000/160000 [==============================] - 102s 636us/step - loss: 0.0413 - accuracy: 0.9856 - val_loss: 0.0922 - val_accuracy: 0.9702\n",
            "Epoch 32/100\n",
            "160000/160000 [==============================] - 102s 637us/step - loss: 0.0388 - accuracy: 0.9865 - val_loss: 0.0932 - val_accuracy: 0.9700\n",
            "Epoch 33/100\n",
            "160000/160000 [==============================] - 102s 637us/step - loss: 0.0367 - accuracy: 0.9873 - val_loss: 0.0965 - val_accuracy: 0.9695\n",
            "Epoch 34/100\n",
            "160000/160000 [==============================] - 102s 637us/step - loss: 0.0354 - accuracy: 0.9878 - val_loss: 0.0979 - val_accuracy: 0.9702\n",
            "Epoch 35/100\n",
            "160000/160000 [==============================] - 105s 654us/step - loss: 0.0334 - accuracy: 0.9888 - val_loss: 0.0975 - val_accuracy: 0.9706\n",
            "Epoch 36/100\n",
            "160000/160000 [==============================] - 104s 651us/step - loss: 0.0305 - accuracy: 0.9897 - val_loss: 0.1048 - val_accuracy: 0.9699\n",
            "Epoch 37/100\n",
            "160000/160000 [==============================] - 103s 645us/step - loss: 0.0303 - accuracy: 0.9899 - val_loss: 0.1059 - val_accuracy: 0.9695\n",
            "Epoch 38/100\n",
            "160000/160000 [==============================] - 103s 643us/step - loss: 0.0285 - accuracy: 0.9905 - val_loss: 0.1071 - val_accuracy: 0.9702\n",
            "Epoch 39/100\n",
            "160000/160000 [==============================] - 103s 643us/step - loss: 0.0270 - accuracy: 0.9911 - val_loss: 0.1091 - val_accuracy: 0.9697\n",
            "Epoch 40/100\n",
            "160000/160000 [==============================] - 103s 643us/step - loss: 0.0251 - accuracy: 0.9917 - val_loss: 0.1134 - val_accuracy: 0.9695\n",
            "Epoch 41/100\n",
            "160000/160000 [==============================] - 103s 644us/step - loss: 0.0228 - accuracy: 0.9927 - val_loss: 0.1123 - val_accuracy: 0.9702\n",
            "Epoch 42/100\n",
            "160000/160000 [==============================] - 103s 643us/step - loss: 0.0229 - accuracy: 0.9927 - val_loss: 0.1187 - val_accuracy: 0.9694\n",
            "Epoch 43/100\n",
            " 32320/160000 [=====>........................] - ETA: 1:19 - loss: 0.0186 - accuracy: 0.9945"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-57-ff6f34cedef0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mD:\\Installed_SW\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[1;32mD:\\Installed_SW\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Installed_SW\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[1;32mD:\\Installed_SW\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VbA1mioi60__",
        "outputId": "75979272-7092-48a0-bf36-eff71081d4fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "model.fit(X_train, y_train,batch_size=64,epochs=100,validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ff6f34cedef0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TDUEsGy7WaI6",
        "colab": {}
      },
      "source": [
        "# Decoding the onehot encoded vector and converting data back to strings\n",
        "\n",
        "def decode(data):\n",
        "  data=data.argmax(axis=-1)\n",
        "  out=[]\n",
        "  for j in range(len(data)):\n",
        "    out.append(''.join([indices_char[i] for i in data[j]]))\n",
        "  return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_1zQH3_f-pZG",
        "outputId": "c4ac59ac-f66c-479f-ce9a-da72c46c2fc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# train data\n",
        "decode(X_train[1:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['    1*771',\n",
              " '  341*577',\n",
              " '    0*598',\n",
              " '     9*78',\n",
              " '     0+46',\n",
              " '   73*805',\n",
              " '      5+2',\n",
              " '    9/989',\n",
              " '    2-695']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZNhHH-ND-pV5",
        "outputId": "d86cf2fc-596a-42b5-ebcd-f2342a55cdda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# y_train \n",
        "decode(y_train[1:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['  28', ' -58', '  -8', '-423', ' 680', '  62', ' -17', ' -88', '  33']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9A8xdQ2dZNFK",
        "colab": {}
      },
      "source": [
        "# model predictions\n",
        "pred=model.predict(X_train[1:10])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RNzVzouk-pTR",
        "outputId": "fd9f7ef6-afa7-4b6f-835b-61b1b98bac78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# decoding model predictions\n",
        "decode(pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['  28', ' -58', '  -8', '-423', ' 680', '  62', ' -17', ' -88', '  33']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iPSymMjbd9M-"
      },
      "source": [
        "## Problems with this approach:\n",
        "In the general case, information about the entire input sequence is necessary in order to start generating the target sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oHYS7IVO-pJM",
        "colab": {}
      },
      "source": [
        "# What I understood is bp happens at each time step. It is not waiting for all the input to be given. \n",
        "# The process will start as soon as it sees some input.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "whp_0dDv-pF4",
        "colab": {}
      },
      "source": [
        "# But in language prediction tasks we want the decoder to wait till all the input is given and then start the deocding process.\n",
        "# Often in most of the cases we don't have fixed input and fixed output like in machine translation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RHtWdsqO-pDm",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GG6OEYD7-pBq",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FbLiDYp4-o-p",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uaxfskUz-o73",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bqCal316-o5R",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OCOLmPFu-o2r",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LQ6VXLp0-o0P",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RNt9qDM7-oxl",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}